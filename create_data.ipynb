{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_stocks = [\n",
    "        'RELIANCE.NS',   # Reliance Industries\n",
    "        'TCS.NS',        # Tata Consultancy Services\n",
    "        'HDFCBANK.NS',   # HDFC Bank\n",
    "        'INFY.NS',       # Infosys\n",
    "        'HINDUNILVR.NS', # Hindustan Unilever\n",
    "        'ICICIBANK.NS',  # ICICI Bank\n",
    "        'SBIN.NS',       # State Bank of India\n",
    "        'BAJFINANCE.NS', # Bajaj Finance\n",
    "        'WIPRO.NS',      # Wipro\n",
    "        'AXISBANK.NS'    # Axis Bank\n",
    "    ]\n",
    "us_stocks = ['AAPL', 'MSFT', 'GOOGL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_DIR = \"hourly_data\"  # Directory to store CSV files\n",
    "START_DATE = datetime.today() - pd.DateOffset(years=1)  # One year back from today\n",
    "END_DATE = datetime.today().strftime('%Y-%m-%d')  # Today's date\n",
    "\n",
    "# --- Get S&P 500 Tickers ---\n",
    "def get_sp500_tickers():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    tickers = []\n",
    "    \n",
    "    for row in table.findAll('tr')[1:]:  # Skip header\n",
    "        cells = row.findAll('td')\n",
    "        if len(cells) > 0:\n",
    "            ticker = cells[0].text.strip()\n",
    "            tickers.append(ticker.replace('.', '-'))  # Fix tickers like BRK.B\n",
    "    \n",
    "    return tickers\n",
    "def get_indian_tickers():\n",
    "    \"\"\"Predefined list of common Indian stocks (NSE)\"\"\"\n",
    "    return indian_stocks\n",
    "# --- Download Hourly Data ---\n",
    "def download_hourly_data(tickers, max_retries=3):\n",
    "    # Create data directory\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    # Get existing files to skip already downloaded tickers\n",
    "    downloaded = set([f.split('.')[0] for f in os.listdir(DATA_DIR)])\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        if ticker in downloaded:\n",
    "            print(f\"Skipping {ticker} (already downloaded)\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Downloading {ticker} ({i+1}/{len(tickers)})\")\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Download data with 1-hour intervals\n",
    "                data = yf.download(\n",
    "                    ticker,\n",
    "                    start=START_DATE,\n",
    "                    end=END_DATE,\n",
    "                    interval='1h',\n",
    "                    progress=True\n",
    "                )\n",
    "                \n",
    "                if not data.empty:\n",
    "                    # Add technical features\n",
    "                    #data['Returns'] = data['Adj Close'].pct_change()\n",
    "                    #data['SMA_20'] = data['Adj Close'].rolling(20).mean()\n",
    "                    \n",
    "                    # Save to CSV\n",
    "                    filename = os.path.join(DATA_DIR, f\"{ticker}_hourly.csv\")\n",
    "                    data.to_csv(filename)\n",
    "                    print(f\"Saved {filename}\")\n",
    "                else:\n",
    "                    print(f\"No data found for {ticker}\")\n",
    "                \n",
    "                break  # Success - exit retry loop\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt+1} failed for {ticker}: {str(e)}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2)  # Add delay between retries\n",
    "                else:\n",
    "                    print(f\"Failed to download {ticker} after {max_retries} attempts\")\n",
    "        \n",
    "        time.sleep(1)  # Be polite to Yahoo's servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/f8dm2s3j49v8_h2b1tdytvmr0000gn/T/ipykernel_47195/3888527907.py:22: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n",
      "  for row in table.findAll('tr')[1:]:  # Skip header\n",
      "/var/folders/g6/f8dm2s3j49v8_h2b1tdytvmr0000gn/T/ipykernel_47195/3888527907.py:23: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n",
      "  cells = row.findAll('td')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all S&P 500 tickers\n",
    "sp500_tickers = get_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_tickers = us_stocks\n",
    "indian_tickers =  get_indian_tickers()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading RELIANCE.NS (1/3)\n",
      "Saved hourly_data/RELIANCE.NS_hourly.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TCS.NS (2/3)\n",
      "Saved hourly_data/TCS.NS_hourly.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading HDFCBANK.NS (3/3)\n",
      "Saved hourly_data/HDFCBANK.NS_hourly.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AAPL (1/3)\n",
      "Saved hourly_data/AAPL_hourly.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MSFT (2/3)\n",
      "Saved hourly_data/MSFT_hourly.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GOOGL (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hourly_data/GOOGL_hourly.csv\n"
     ]
    }
   ],
   "source": [
    "download_hourly_data(indian_tickers)\n",
    "download_hourly_data(sp500_tickers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
